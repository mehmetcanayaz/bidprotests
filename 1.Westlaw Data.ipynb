{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7b1ead-e035-4b88-bd73-8a2b78fc47c1",
   "metadata": {},
   "source": [
    "### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a91bdc-8933-4bbd-a30c-0755349bcd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-docx in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from python-docx) (4.10.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from python-docx) (4.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (305.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from python-docx) (4.9.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from python-docx) (4.10.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\muc574\\appdata\\local\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas python-docx\n",
    "!pip install pywin32 python-docx\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6de507-4d1e-4425-825e-a32bf9a25a8c",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85999f8e-fc68-4d52-bd26-288aa1d1b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import csv\n",
    "import os\n",
    "import re  # Import the regular expression module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40d82ab-4759-433c-b239-d8c6faab2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped 1.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1\n",
      "Unzipped 10.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\10\n",
      "Unzipped 11.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\11\n",
      "Unzipped 12.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\12\n",
      "Unzipped 13.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\13\n",
      "Unzipped 14.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\14\n",
      "Unzipped 15.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\15\n",
      "Unzipped 16.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\16\n",
      "Unzipped 17.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\17\n",
      "Unzipped 18.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\18\n",
      "Unzipped 19.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\19\n",
      "Unzipped 2.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\2\n",
      "Unzipped 20.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\20\n",
      "Unzipped 21.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\21\n",
      "Unzipped 22.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\22\n",
      "Unzipped 23.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\23\n",
      "Unzipped 24.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\24\n",
      "Unzipped 25.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\25\n",
      "Unzipped 26.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\26\n",
      "Unzipped 27.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\27\n",
      "Unzipped 28.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\28\n",
      "Unzipped 29.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\29\n",
      "Unzipped 3.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\3\n",
      "Unzipped 30.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\30\n",
      "Unzipped 31.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\31\n",
      "Unzipped 32.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\32\n",
      "Unzipped 33.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\33\n",
      "Unzipped 4.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\4\n",
      "Unzipped 5.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\5\n",
      "Unzipped 6.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\6\n",
      "Unzipped 7.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\7\n",
      "Unzipped 8.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\8\n",
      "Unzipped 9.zip into C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\9\n"
     ]
    }
   ],
   "source": [
    "# Define the path where the ZIP files are located\n",
    "zip_files_path = 'C:\\\\Users\\\\muc574\\\\Bid Protest\\\\WestLaw Data\\\\Data'\n",
    "unzip_folders_path = zip_files_path  # Assuming you want to unzip in the same location\n",
    "\n",
    "# Unzip each ZIP file into a different subfolder\n",
    "for filename in os.listdir(zip_files_path):\n",
    "    if filename.endswith('.zip'):\n",
    "        # Create a subfolder for the contents of this ZIP file\n",
    "        subfolder_name = os.path.splitext(filename)[0]\n",
    "        subfolder_path = os.path.join(unzip_folders_path, subfolder_name)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "        \n",
    "        # Unzip the ZIP file into the subfolder\n",
    "        zip_file_path = os.path.join(zip_files_path, filename)\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(subfolder_path)\n",
    "        print(f\"Unzipped {filename} into {subfolder_path}\")\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d290ed6-60ee-4fa2-8d71-8d033e48b403",
   "metadata": {},
   "source": [
    "## Data Collection and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f88cf8d-e545-43ab-9257-574578a253c5",
   "metadata": {},
   "source": [
    "### Step 1 - Read Doc Files into CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9108d5-7ec9-4e7d-9c63-39a116dd2199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##export conclusion sections\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "def save_final_clean_text_to_csv(root_dir, csv_filename='final_clean_text.csv'):\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Subdir', 'Filename', 'Final Clean Text'])\n",
    "\n",
    "        # Cleanup pattern to remove RTF control words, formatting characters, braces, and reduce all kinds of whitespace\n",
    "        cleanup_pattern = re.compile(r'(\\\\par|\\\\[a-z]+\\d*|\\{\\}|\\{|\\}|\\n|\\r|\\t|\\f|\\v|\\s{2,})')\n",
    "\n",
    "        for subdir, dirs, files in os.walk(root_dir):\n",
    "            for filename in files:\n",
    "                if filename.endswith('.doc'):  # Adjust as necessary for your file types\n",
    "                    file_path = os.path.join(subdir, filename)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                            content = file.read()\n",
    "\n",
    "                            # Find all occurrences of \"conclusion\" and \"All Citations\"\n",
    "                            conclusions = [(m.start(0), m.end(0)) for m in re.finditer('conclusion', content, re.IGNORECASE | re.DOTALL)]\n",
    "                            all_citations = [(m.start(0), m.end(0)) for m in re.finditer('All Citations', content, re.IGNORECASE | re.DOTALL)]\n",
    "\n",
    "                            # Determine the last \"conclusion\" before the last \"All Citations\", if \"All Citations\" exists\n",
    "                            if all_citations:\n",
    "                                last_citation_start, _ = all_citations[-1]\n",
    "                                conclusions_before_last_citation = [end for start, end in conclusions if start < last_citation_start]\n",
    "                                if conclusions_before_last_citation:\n",
    "                                    conclusion_end = conclusions_before_last_citation[-1]\n",
    "                                    all_citations_start = last_citation_start\n",
    "                                    text_after_conclusion_before_citations = content[conclusion_end:all_citations_start].strip()\n",
    "                                else:\n",
    "                                    continue  # Skip if no valid conclusion before last \"All Citations\"\n",
    "                            else:\n",
    "                                # If \"All Citations\" does not exist, use the last \"conclusion\"\n",
    "                                if conclusions:\n",
    "                                    _, conclusion_end = conclusions[-1]\n",
    "                                    text_after_conclusion_before_citations = content[conclusion_end:].strip()\n",
    "                                else:\n",
    "                                    continue  # Skip if no \"conclusion\" at all\n",
    "\n",
    "                            # Further cleanup of the text, including reducing excessive whitespace\n",
    "                            clean_text = re.sub(cleanup_pattern, ' ', text_after_conclusion_before_citations).strip()\n",
    "                            # Additional step to ensure the text is a coherent paragraph\n",
    "                            coherent_paragraph = ' '.join(clean_text.split())\n",
    "                            #print(f\"File: {filename}, Final Clean Text: {coherent_paragraph[:100]}...\")\n",
    "                            csvwriter.writerow([subdir, filename, coherent_paragraph])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {filename}: {e}\")\n",
    "\n",
    "# Define the root directory\n",
    "root_directory = 'C:\\\\Users\\\\muc574\\\\Bid Protest\\\\WestLaw Data\\\\Data'\n",
    "\n",
    "# Execute the function with the root directory as its argument\n",
    "save_final_clean_text_to_csv(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8daf671-220a-4717-ad98-adf59b5bba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .doc files under C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data: 3405\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory\n",
    "root_dir = 'C:\\\\Users\\\\muc574\\\\Bid Protest\\\\WestLaw Data\\\\Data'\n",
    "\n",
    "# Counter for .doc files\n",
    "doc_file_count = 0\n",
    "\n",
    "# Walk through the directory and its subdirectories\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.doc'):\n",
    "            doc_file_count += 1\n",
    "\n",
    "# Print the number of .doc files\n",
    "print(f\"Number of .doc files under {root_dir}: {doc_file_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a34ee-dd28-49da-9ecc-03caf9ce5fb2",
   "metadata": {},
   "source": [
    "### Step 2 - Convert to XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c752147d-3728-4694-b112-f516919ec377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('final_clean_text.csv')\n",
    "\n",
    "# Filter rows where 'Subdir' column contains the specified path\n",
    "filtered_df = df[df['Subdir'].str.contains(r'C:\\\\Users\\\\muc574\\\\Bid Protest\\\\WestLaw Data\\\\Data\\\\.*', regex=True)]\n",
    "\n",
    "# Save the filtered data to an XLSX file using openpyxl\n",
    "filtered_df.to_excel('final_clean_text_2.xlsx', index=False, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f597a17f-4568-4621-96aa-2fa2a4e8fea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subdir</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Final Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>001 - PDS Consultants Inc v United States.doc</td>\n",
       "      <td>For all of these reasons, the court GRANTS IFB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>002 - Veterans Contracting Group Inc v United ...</td>\n",
       "      <td>For the reasons stated, Veterans motion for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>003 - Q Integrated Companies LLC v United Stat...</td>\n",
       "      <td>For the foregoing reasons, Q Integrated is awa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>004 - In re Global Computer Enterprises Inc.doc</td>\n",
       "      <td>For the foregoing reasons, the Court finds in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>005 - AT And T Corp v United States.doc</td>\n",
       "      <td>For the foregoing reasons, the Court concludes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Subdir  \\\n",
       "0  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "1  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "2  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "3  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "4  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "\n",
       "                                            Filename  \\\n",
       "0      001 - PDS Consultants Inc v United States.doc   \n",
       "1  002 - Veterans Contracting Group Inc v United ...   \n",
       "2  003 - Q Integrated Companies LLC v United Stat...   \n",
       "3    004 - In re Global Computer Enterprises Inc.doc   \n",
       "4            005 - AT And T Corp v United States.doc   \n",
       "\n",
       "                                    Final Clean Text  \n",
       "0  For all of these reasons, the court GRANTS IFB...  \n",
       "1  For the reasons stated, Veterans motion for a ...  \n",
       "2  For the foregoing reasons, Q Integrated is awa...  \n",
       "3  For the foregoing reasons, the Court finds in ...  \n",
       "4  For the foregoing reasons, the Court concludes...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba33ca9-f54a-4087-b0af-34e994e434ab",
   "metadata": {},
   "source": [
    "### Step 3 - Now generate data for excluded files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a3a74-cfd1-4ea1-be70-9a9a089406a1",
   "metadata": {},
   "source": [
    "#### Identify excluded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34379f8-3cb5-4454-9c27-dfb07ed1f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2817,)\n",
      "587\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory\n",
    "root_dir = 'C:\\\\Users\\\\muc574\\\\Bid Protest\\\\WestLaw Data\\\\Data'\n",
    "\n",
    "# Read the Excel file to get the list of subdirectories already included\n",
    "df = pd.read_excel('final_clean_text_2.xlsx', engine='openpyxl')\n",
    "included_subdirs = set(df['Filename'])\n",
    "print(df['Filename'].shape)\n",
    "\n",
    "# List to store paths of .doc files not included in the Excel file\n",
    "excluded_files = []\n",
    "# List to store paths of .doc files not included in the Excel file\n",
    "excluded_files_long = []\n",
    "\n",
    "\n",
    "# Walk through the directory and its subdirectories\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.doc'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            #print(file)\n",
    "            # Check if the file's directory is not in the list of included subdirectories\n",
    "            if file not in included_subdirs:\n",
    "                excluded_files.append(file)\n",
    "                excluded_files_long.append(file_path)\n",
    "\n",
    "print(len(excluded_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d125b620-a83d-43e3-8c40-7beabf39e3bc",
   "metadata": {},
   "source": [
    "#### Extract info from excluded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e2a7f3-6dec-4f73-8cad-161fd4adcb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "def clean_and_extract_last_100_chars(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            # Split and remove all text after \"All Citations\"\n",
    "            content = re.split('All Citations', content, flags=re.IGNORECASE)[0]\n",
    "            # Extended cleanup pattern to also remove specific patterns and sequences of spaces\n",
    "            cleanup_pattern = re.compile(\n",
    "                r'(\\\\par|\\\\[a-z]+\\d*|\\{\\}|\\{|\\}|\\n|\\r|\\t|\\f|\\v|\\s{2,}|\\\\[*]co_allCitations_\\d+\\\\[*]co_allCitations_\\d+|\\s{5,})'\n",
    "            )\n",
    "            clean_content = re.sub(cleanup_pattern, '', content).strip()\n",
    "            return clean_content[-1000:]\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Prepare to write to a CSV file\n",
    "with open('additionaldata.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Subdir', 'Filename', 'Final Clean Text'])\n",
    "\n",
    "    for file_path in excluded_files_long:\n",
    "        #print(file_path)\n",
    "        last_100_chars = clean_and_extract_last_100_chars(file_path)\n",
    "        if last_100_chars:\n",
    "            directory, filename = os.path.split(file_path)\n",
    "            csvwriter.writerow([directory, filename, last_100_chars])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672de3c8-b17c-41ba-a5f7-b35eaa3e3978",
   "metadata": {},
   "source": [
    "### Step 4 - Merge all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea0f07b3-bcbc-4caa-8cc8-9983f6866987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muc574\\AppData\\Local\\Temp\\ipykernel_11452\\1100021393.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_combined = df_csv.append(df_excel, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in additionaldata.csv: 587\n",
      "Rows in final_clean_text_2.xlsx: 2817\n",
      "Rows in combined dataframe: 3404\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the CSV file\n",
    "df_csv = pd.read_csv('additionaldata.csv')\n",
    "\n",
    "# Read the Excel file\n",
    "df_excel = pd.read_excel('final_clean_text_2.xlsx', engine='openpyxl')\n",
    "\n",
    "# Append the dataframes\n",
    "df_combined = df_csv.append(df_excel, ignore_index=True)\n",
    "\n",
    "# Export the combined dataframe to a new Excel file\n",
    "df_combined.to_excel('final_clean_text_3.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "# Confirm the number of rows in the final dataframe is equal to the sum of the rows in each\n",
    "print(f\"Rows in additionaldata.csv: {df_csv.shape[0]}\")\n",
    "print(f\"Rows in final_clean_text_2.xlsx: {df_excel.shape[0]}\")\n",
    "print(f\"Rows in combined dataframe: {df_combined.shape[0]}\")\n",
    "assert df_combined.shape[0] == df_csv.shape[0] + df_excel.shape[0], \"Row counts do not match.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021901d-8c73-4faa-83fb-ed2ff6c529f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3e8db2-2dcc-4c24-979c-8abe204a30b2",
   "metadata": {},
   "source": [
    "### Step 5 - Calculate rejection rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a439932-72bc-4992-902e-8e2d035ffec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subdir</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Final Clean Text</th>\n",
       "      <th>contains_denied</th>\n",
       "      <th>contains_rejected</th>\n",
       "      <th>contains_dismissed</th>\n",
       "      <th>contains_remanded</th>\n",
       "      <th>total_unsuccessful</th>\n",
       "      <th>contains_settled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>007 - Mail Transportation Inc v United States.doc</td>\n",
       "      <td>HYPERLINK \"https://www.westlaw.com/Link/Docume...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>008 - Mail Transportation Inc v United States.doc</td>\n",
       "      <td>conversion serves the public interest, an inj...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>010 - Account Control Technology Inc v United ...</td>\n",
       "      <td>a947fe08ef5e04eeedbf79e1eebe33c5c31feedea87c41...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>011 - Van Ru Credit Corporation v United State...</td>\n",
       "      <td>5ad879fb8d2e86f4d2245807cb00009aa61f3e7c4892e4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1</td>\n",
       "      <td>012 - Collection Technology Inc v United State...</td>\n",
       "      <td>686363039e5feb04f01211168160a6f6e8d123ad561b1c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Subdir  \\\n",
       "0  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "1  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "2  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "3  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "4  C:\\Users\\muc574\\Bid Protest\\WestLaw Data\\Data\\1   \n",
       "\n",
       "                                            Filename  \\\n",
       "0  007 - Mail Transportation Inc v United States.doc   \n",
       "1  008 - Mail Transportation Inc v United States.doc   \n",
       "2  010 - Account Control Technology Inc v United ...   \n",
       "3  011 - Van Ru Credit Corporation v United State...   \n",
       "4  012 - Collection Technology Inc v United State...   \n",
       "\n",
       "                                    Final Clean Text  contains_denied  \\\n",
       "0  HYPERLINK \"https://www.westlaw.com/Link/Docume...                0   \n",
       "1   conversion serves the public interest, an inj...                1   \n",
       "2  a947fe08ef5e04eeedbf79e1eebe33c5c31feedea87c41...                0   \n",
       "3  5ad879fb8d2e86f4d2245807cb00009aa61f3e7c4892e4...                0   \n",
       "4  686363039e5feb04f01211168160a6f6e8d123ad561b1c...                0   \n",
       "\n",
       "   contains_rejected  contains_dismissed  contains_remanded  \\\n",
       "0                  0                   0                  0   \n",
       "1                  0                   0                  0   \n",
       "2                  0                   0                  0   \n",
       "3                  0                   0                  0   \n",
       "4                  0                   0                  0   \n",
       "\n",
       "   total_unsuccessful  contains_settled  \n",
       "0                   0                 0  \n",
       "1                   1                 0  \n",
       "2                   0                 0  \n",
       "3                   0                 0  \n",
       "4                   0                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('final_clean_text_3.xlsx', engine='openpyxl')\n",
    "\n",
    "# Function to check if the patterns \"denied\" or \"sustained\" exist in the text\n",
    "def contains_pattern(text, pattern):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return 1 if re.search(pattern, text, re.IGNORECASE) else 0\n",
    "\n",
    "# Generate dummy variables\n",
    "df['contains_denied'] = df['Final Clean Text'].apply(lambda x: contains_pattern(x, 'denied'))\n",
    "df['contains_rejected'] = df['Final Clean Text'].apply(lambda x: contains_pattern(x, 'rejected'))\n",
    "df['contains_dismissed'] = df['Final Clean Text'].apply(lambda x: contains_pattern(x, 'dismissed'))\n",
    "df['contains_remanded'] = df['Final Clean Text'].apply(lambda x: contains_pattern(x, 'remanded'))\n",
    "\n",
    "df['total_unsuccessful'] = df['contains_denied'] + df['contains_rejected'] + df['contains_dismissed'] +df['contains_remanded']\n",
    "\n",
    "df['contains_settled'] = df['Final Clean Text'].apply(lambda x: contains_pattern(x, 'settled'))\n",
    "\n",
    "# Optional: save the updated dataframe with dummy variables to a new Excel file\n",
    "df.to_excel('final_clean_text_4.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f0ab6f-6a89-4c13-9c76-4eb0ff0da1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contains_denied</th>\n",
       "      <th>contains_rejected</th>\n",
       "      <th>contains_dismissed</th>\n",
       "      <th>contains_remanded</th>\n",
       "      <th>total_unsuccessful</th>\n",
       "      <th>contains_settled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3404.000000</td>\n",
       "      <td>3404.000000</td>\n",
       "      <td>3404.000000</td>\n",
       "      <td>3404.000000</td>\n",
       "      <td>3404.000000</td>\n",
       "      <td>3404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.454465</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.159224</td>\n",
       "      <td>0.056110</td>\n",
       "      <td>0.706816</td>\n",
       "      <td>0.017920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497995</td>\n",
       "      <td>0.188827</td>\n",
       "      <td>0.365939</td>\n",
       "      <td>0.230169</td>\n",
       "      <td>0.683847</td>\n",
       "      <td>0.132681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       contains_denied  contains_rejected  contains_dismissed  \\\n",
       "count      3404.000000        3404.000000         3404.000000   \n",
       "mean          0.454465           0.037015            0.159224   \n",
       "std           0.497995           0.188827            0.365939   \n",
       "min           0.000000           0.000000            0.000000   \n",
       "25%           0.000000           0.000000            0.000000   \n",
       "50%           0.000000           0.000000            0.000000   \n",
       "75%           1.000000           0.000000            0.000000   \n",
       "max           1.000000           1.000000            1.000000   \n",
       "\n",
       "       contains_remanded  total_unsuccessful  contains_settled  \n",
       "count        3404.000000         3404.000000       3404.000000  \n",
       "mean            0.056110            0.706816          0.017920  \n",
       "std             0.230169            0.683847          0.132681  \n",
       "min             0.000000            0.000000          0.000000  \n",
       "25%             0.000000            0.000000          0.000000  \n",
       "50%             0.000000            1.000000          0.000000  \n",
       "75%             0.000000            1.000000          0.000000  \n",
       "max             1.000000            4.000000          1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0964fa-a2b2-4411-bc3f-e26ebf7dcbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959701e3-d4e4-46fd-b5b1-496087a99559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68331d33-3993-4b76-b2b5-9330688e9f6a",
   "metadata": {},
   "source": [
    "### Step 6 - ( '\\\\$' in paragraph and  'cost' in paragraph) or ( '\\\\$' in paragraph and  'contract' in paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e09f59-51fb-42af-b062-534b2e51a41e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   1%|          | 34/3405 [00:09<16:12,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 9.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#format 1\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def save_paragraphs_with_dollar_sign_to_csv(root_dir, csv_filename='paragraphs_with_dollar_format1.csv'):\n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    # Prepare to count files for progress bar\n",
    "    total_files = sum([len(files) for r, d, files in os.walk(root_dir) if any(\".doc\" in f for f in files)])\n",
    "    processed_files = 0\n",
    "\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['subdir', 'Filename', 'Paragraph'])  # Write the header\n",
    "\n",
    "        # Iterate through all subdirectories of the root directory\n",
    "        for subdir, dirs, files in tqdm(os.walk(root_dir), total=total_files, desc=\"Processing files\"):\n",
    "            for filename in files:\n",
    "                if \".doc\" in filename:\n",
    "                    file_path = os.path.join(subdir, filename)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                            content = file.read()  # Read the entire file into a single string\n",
    "                            paragraphs = content.split('\\n')  # Split the content into paragraphs\n",
    "                            for paragraph in paragraphs:\n",
    "                                if ( '$' in paragraph and  'cost' in paragraph) or ( '$' in paragraph and  'contract' in paragraph) :\n",
    "                                    #print(f\"File: {filename}, Paragraph with $: {paragraph}\")  # Optional: printing\n",
    "                                    csvwriter.writerow([subdir, filename, paragraph])  # Save to CSV\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {filename}: {e}\")\n",
    "                    finally:\n",
    "                        processed_files += 1\n",
    "                        # Update progress manually if necessary\n",
    "                        # tqdm.write(f\"Processed {processed_files} / {total_files} files\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Define the root directory\n",
    "root_directory = 'C:\\\\Users\\\\muc574\\\\Bid Protest\\\\WestLaw Data\\\\Data'\n",
    "\n",
    "# Execute the function with the root directory as its argument\n",
    "save_paragraphs_with_dollar_sign_to_csv(root_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bc1e1-bc36-44d6-8c6d-7996f01e4712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e26ec55a-10e5-4e7e-9a81-022fbfbab967",
   "metadata": {},
   "source": [
    "### Step 7 - Estimate the economic magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4b7c8f0-0843-4d64-ac77-6d165fe6abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully aggregated and exported to output_1.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'paragraphs_with_dollar_format1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Creating a unique identifier for each document\n",
    "df['document_id'] = df['subdir'] + '\\\\' + df['Filename']\n",
    "\n",
    "# Initialize columns for estimates and snippets\n",
    "df['total_cost_estimate'] = \"No Clear Cost Estimate\"\n",
    "df['contract_amount_estimate'] = \"No Clear Contract Amount\"\n",
    "df['total_cost_snippet'] = \"\"\n",
    "df['contract_amount_snippet'] = \"\"\n",
    "df['per_item_or_unit_dummy'] = 0\n",
    "\n",
    "# Define patterns for cost and contract amount identification\n",
    "cost_pattern = re.compile(r'\\$\\d+(?:,\\d{3})*(?:\\.\\d+)?(?: million| billion)?', re.IGNORECASE)\n",
    "contract_amount_phrases = ['contract amount', 'contract sum', 'award']\n",
    "total_cost_phrases = ['total cost', 'damages', 'cost', 'bid cost', 'attorney fee', 'labor cost', 'indirect cost', 'legal fee', 'fee']\n",
    "\n",
    "# Function to convert formatted string values to numeric values\n",
    "def convert_to_numeric(value):\n",
    "    number = re.findall(r'\\d+(?:,\\d{3})*(?:\\.\\d+)?', value.replace(\",\", \"\"))\n",
    "    if number:\n",
    "        number = float(number[0].replace(\",\", \"\"))\n",
    "        if 'million' in value.lower():\n",
    "            return int(number) * 1e6\n",
    "        elif 'billion' in value.lower():\n",
    "            return int(number) * 1e9\n",
    "        else:\n",
    "            return int(number)\n",
    "    return int(value)\n",
    "\n",
    "# Iterate over rows to extract information\n",
    "for index, row in df.iterrows():\n",
    "    if \"per item\" in row['Paragraph'] or \"per unit\" in row['Paragraph']:\n",
    "        df.at[index, 'per_item_or_unit_dummy'] = 1\n",
    "    \n",
    "    if any(phrase in row['Paragraph'].lower() for phrase in total_cost_phrases):\n",
    "        matches = cost_pattern.findall(row['Paragraph'])\n",
    "        if matches:\n",
    "            # Convert and assign the numeric value\n",
    "            numeric_value = convert_to_numeric(matches[0])\n",
    "            df.at[index, 'total_cost_estimate'] = numeric_value\n",
    "            df.at[index, 'total_cost_snippet'] = row['Paragraph'][:100]\n",
    "    \n",
    "    if any(phrase in row['Paragraph'].lower() for phrase in contract_amount_phrases):\n",
    "        matches = cost_pattern.findall(row['Paragraph'])\n",
    "        if matches:\n",
    "            # Convert and assign the numeric value\n",
    "            numeric_value = convert_to_numeric(matches[0])\n",
    "            df.at[index, 'contract_amount_estimate'] = numeric_value\n",
    "            df.at[index, 'contract_amount_snippet'] = row['Paragraph'][:100]\n",
    "\n",
    "# Aggregating rows by document_id to ensure one row per document\n",
    "aggregated_df = df.groupby('document_id').agg({\n",
    "    'total_cost_estimate': 'last',\n",
    "    'contract_amount_estimate': 'last',\n",
    "    'per_item_or_unit_dummy': 'max',\n",
    "    'total_cost_snippet': 'first',\n",
    "    'contract_amount_snippet': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Exporting the aggregated data to an Excel file\n",
    "output_path = 'output_1.xlsx'\n",
    "aggregated_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully aggregated and exported to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba7e82-e639-4c3a-9cf2-c5b9a08b0bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a18ed7-8ac1-4acd-9880-15d50aa4cce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logged_total_cost_estimate_winsorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1,113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      logged_total_cost_estimate_winsorized\n",
       "count                               1,113.0\n",
       "mean                                  12.46\n",
       "std                                    4.48\n",
       "min                                    2.83\n",
       "25%                                    9.62\n",
       "50%                                   12.75\n",
       "75%                                   15.89\n",
       "max                                   19.79"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings from pandas\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Assuming aggregated_df is already defined\n",
    "\n",
    "# Make a copy of aggregated_df to avoid changing the original DataFrame\n",
    "df = aggregated_df.copy()\n",
    "\n",
    "# Convert 'total_cost_estimate' from string to numeric, setting errors='coerce' to turn non-convertible values into NaN\n",
    "df['total_cost_estimate'] = pd.to_numeric(df['total_cost_estimate'], errors='coerce')\n",
    "df['contract_amount_estimate'] = pd.to_numeric(df['contract_amount_estimate'], errors='coerce')\n",
    "\n",
    "# Replace missing 'total_cost_estimate' with 'contract_amount_estimate' where applicable\n",
    "df.loc[df['total_cost_estimate'].isnull() & df['contract_amount_estimate'].notnull(), 'total_cost_estimate'] = df['contract_amount_estimate']\n",
    "\n",
    "# Filter rows where 'total_cost_estimate' is not NaN (after replacement)\n",
    "df_1 = df[df['total_cost_estimate'].notnull()].copy()\n",
    "\n",
    "# Ensure 'contract_amount_estimate' is numeric (should already be, but this is to double-check)\n",
    "df_1['contract_amount_estimate'] = pd.to_numeric(df_1['contract_amount_estimate'], errors='coerce')\n",
    "\n",
    "# Add logged variables of the numeric columns\n",
    "df_1['logged_total_cost_estimate'] = np.log1p(df_1['total_cost_estimate'])\n",
    "df_1['logged_contract_amount_estimate'] = np.log1p(df_1['contract_amount_estimate'])\n",
    "\n",
    "# Winsorize the numeric columns at 2.5% for both tails\n",
    "df_1['total_cost_estimate_winsorized'] = winsorize(df_1['total_cost_estimate'], limits=[0.05, 0.05])\n",
    "df_1['contract_amount_estimate_winsorized'] = winsorize(df_1['contract_amount_estimate'], limits=[0.05, 0.05])\n",
    "\n",
    "# Winsorize the logged columns\n",
    "df_1['logged_total_cost_estimate_winsorized'] = winsorize(df_1['logged_total_cost_estimate'], limits=[0.05, 0.05])\n",
    "df_1['logged_contract_amount_estimate_winsorized'] = winsorize(df_1['logged_contract_amount_estimate'], limits=[0.05, 0.05])\n",
    "\n",
    "# Keep only the relevant columns\n",
    "columns_to_keep = ['logged_total_cost_estimate_winsorized']\n",
    "df_1 = df_1[columns_to_keep]\n",
    "\n",
    "# Describe the winsorized and logged variables\n",
    "description = df_1.describe()\n",
    "\n",
    "# Convert to more readable format by rounding and using applymap to avoid scientific notation\n",
    "description_readable = description.round(2).applymap(lambda x: '{:,}'.format(x))\n",
    "\n",
    "description_readable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e0024-a791-4601-963a-f658e29c89e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
